# -*- coding: utf-8 -*-
"""BinaryClassificationDNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11Cl9y87qERqifr4WnqdBhxQbdscgZUxi
"""

# We will now be importing some required libraries

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

#Loading the dataset
dataset = pd.read_csv('drive/My Drive/Data/customers.csv')

X = dataset.iloc[:,3:13].values
y = dataset.iloc[:,13].values

print(X)
print(y)

# Encoding categorical data
# Encoding the Independent Variable

from sklearn.preprocessing import LabelEncoder, OneHotEncoder

#Label Encoding Gender
labelencoder_X = LabelEncoder()
X[:, 2] = labelencoder_X.fit_transform(X[:, 2])

#Dealing with the categorical Geography column
from sklearn.compose import make_column_transformer
onehotencoder = make_column_transformer((OneHotEncoder(), [1]), remainder='passthrough')
X = onehotencoder.fit_transform(X)

#Removing the extra dummy variable
X = X[:, 1:]

#Splitting the data into Training Set and Test Set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)

#Normalizing the features
from sklearn.preprocessing import StandardScaler
sc_X = StandardScaler()
X_train = sc_X.fit_transform(X_train)
X_test = sc_X.transform(X_test)

import tensorflow as tf

# Define the model
model = tf.keras.models.Sequential()

#Adding a first layer 
model.add(tf.keras.layers.Dense(units=6, input_shape=[11], activation='relu'))
#model.add(tf.keras.layers.Dropout(0.1))

#Adding a second hidden layer
model.add(tf.keras.layers.Dense(units=6, activation='relu'))
#model.add(tf.keras.layers.Dropout(0.1))

#Adding an output layer
model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Train the model
r = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100)

# Evaluate the model, prints loss and accuracy
print("Train score:", model.evaluate(X_train, y_train))
print("Test score:", model.evaluate(X_test, y_test))

# Plot the loss
import matplotlib.pyplot as plt
plt.plot(r.history['loss'], label='loss')
plt.plot(r.history['val_loss'], label='val_loss')
plt.legend()
plt.show()

# Plot the accuracy 
plt.plot(r.history['accuracy'], label='acc')
plt.plot(r.history['val_accuracy'], label='val_acc')
plt.legend()
plt.show()



#Evaluating our Neural Network
from keras.wrappers.scikit_learn import KerasClassifier 
from sklearn.model_selection import cross_val_score

def buildNN():
    # Define the model
    model = tf.keras.models.Sequential()

    #Adding an input layer and one hidden layer
    model.add(tf.keras.layers.Dense(units=6, input_shape=[11], activation='relu'))
    model.add(tf.keras.layers.Dropout(0.1))

    #Adding a second hidden layer
    model.add(tf.keras.layers.Dense(units=6, activation='relu'))
    model.add(tf.keras.layers.Dropout(0.1))

    #Adding an output layer
    model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))

    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    
    return model

classifier = KerasClassifier(build_fn = buildNN, batch_size=10, epochs=100)
accuracy = cross_val_score(estimator = classifier, X = X_train, y=y_train, cv=10, n_jobs=-1,verbose=3)

accuracy

meanAcc = accuracy.mean()
stdDevAcc = accuracy.std()

meanAcc

stdDevAcc

#Hyperparameter tuning of Neural Network
from keras.wrappers.scikit_learn import KerasClassifier 
from sklearn.model_selection import GridSearchCV

def buildNN(optimizer):
    model = tf.keras.models.Sequential()
    model.add(tf.keras.layers.Dense(units=6, input_shape=[11], activation='relu'))
    model.add(tf.keras.layers.Dropout(0.1))
    model.add(tf.keras.layers.Dense(units=6, activation='relu'))
    model.add(tf.keras.layers.Dropout(0.1))
    model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))
    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])
    return model

classifier = KerasClassifier(build_fn = buildNN)
parameters = {'batch_size':[25,32], 'epochs':[100,500], 'optimizer':['adam','rmsprop']}
grid_search = GridSearchCV(estimator =classifier, param_grid=parameters, scoring='accuracy', cv=10)
grid_search = grid_search.fit(X_train, y_train)
best_param = grid_search.best_params_
best_acc=grid_search.best_score_

print(best_param)
print(best_acc)